{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on *Exercise B: Sentiment Analysis* in [Natural Language Processing with Python/NLTK](https://github.com/luchux/ipython-notebook-nltk/blob/master/NLP%20-%20MelbDjango.ipynb) by Luciano M. Guasco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring the `movie_reviews` corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Polarity Dataset Version 2.0\n",
      "Bo Pang and Lillian Lee\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "print(movie_reviews.readme()[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg/cv000_29416.txt',\n",
       " 'neg/cv001_19502.txt',\n",
       " 'neg/cv002_17424.txt',\n",
       " 'neg/cv003_12683.txt',\n",
       " 'neg/cv004_12641.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.fileids()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot : two teen couples go to a church party , drink and then drive . \n",
      "they get into an accident . \n",
      "one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n",
      "what's the deal ? \n",
      "watch the movie and \" sorta \" find out . .\n"
     ]
    }
   ],
   "source": [
    "print(movie_reviews.raw(\"neg/cv000_29416.txt\")[:260])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building and testing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'about', 'above', 'after', 'again']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend('.,[,],(,),;,/,-,\\',?,\",:,<,>,n\\'t,|,#,\\'s,\\\",\\'re,\\'ve,\\'ll,\\'d,\\'re'.split(','))\n",
    "stop_words.extend(',')\n",
    "stop_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "def extract_word_presence_features(words):\n",
    "    return {word: True for word in words if word not in stop_words and word.isalpha()}\n",
    "\n",
    "pos_ids = movie_reviews.fileids('pos')\n",
    "neg_ids = movie_reviews.fileids('neg')\n",
    "\n",
    "len(pos_ids) + len(neg_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOME EXAMPLE WORD PRESENCE FEATURES FOR THE FIRST POSITIVE REVIEW\n",
      "adapted: True\n",
      "success: True\n",
      "like: True\n",
      "plenty: True\n",
      "never: True\n"
     ]
    }
   ],
   "source": [
    "pos_feats = [(extract_word_presence_features(movie_reviews.words(fileids=[f])), 'pos') for f in pos_ids]\n",
    "neg_feats = [(extract_word_presence_features(movie_reviews.words(fileids=[f])), 'neg') for f in neg_ids]\n",
    "\n",
    "print('SOME EXAMPLE WORD PRESENCE FEATURES FOR THE FIRST POSITIVE REVIEW')\n",
    "print('adapted:', pos_feats[0][0]['adapted'])\n",
    "print('success:', pos_feats[0][0]['success'])\n",
    "print('like:', pos_feats[0][0]['like'])\n",
    "print('plenty:', pos_feats[0][0]['plenty'])\n",
    "print('never:', pos_feats[0][0]['never'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_TEST_SPLIT = 3 / 4\n",
    "\n",
    "pos_len_train = int(len(pos_feats) * TRAIN_TEST_SPLIT)\n",
    "neg_len_train = int(len(neg_feats) * TRAIN_TEST_SPLIT)\n",
    "\n",
    "pos_len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "import nltk.classify.util\n",
    "\n",
    "train_feats = neg_feats[:neg_len_train] + pos_feats[:pos_len_train]\n",
    "test_feats = neg_feats[neg_len_train:] + pos_feats[pos_len_train:]\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_feats)\n",
    "\n",
    "print('Accuracy:', round(nltk.classify.util.accuracy(classifier, test_feats), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
      "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
      "               insulting = True              neg : pos    =     13.0 : 1.0\n",
      "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
      "              astounding = True              pos : neg    =     10.3 : 1.0\n",
      "             fascination = True              pos : neg    =     10.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classifying new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'feel', 'miserable', 'amazing', '!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "sentence_1 = \"I feel so miserable, and that's amazing!\"\n",
    "tokens_1 = [word for word in word_tokenize(sentence_1) if word not in stop_words]\n",
    "tokens_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': True, 'feel': True, 'miserable': True, 'amazing': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_1 = extract_word_presence_features(tokens_1)\n",
    "feats_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(feats_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You', 'pathetic', 'fool', 'terrible', 'excuse', 'human']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_2 = \"You are a pathetic fool, a terrible excuse for a human being.\"\n",
    "tokens_2 = [word for word in word_tokenize(sentence_2) if word not in stop_words]\n",
    "tokens_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how adjectives are usually the words that convey the sentiment the most. We can try to extract the adjectives from this sentence and feed only those to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pathetic', 'JJ'), ('terrible', 'JJ')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags_2 = [pos for pos in pos_tag(tokens_2) if pos[1] == 'JJ']\n",
    "pos_tags_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pathetic': True, 'terrible': True}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_2 = extract_word_presence_features([word for (word, _) in pos_tags_2])\n",
    "feats_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(feats_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the classifier, bigram features can be examined using `nltk.util.ngrams`. Because “not funny” is very different from funny”."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
