{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with `nltk.sentiment.SentimentAnalyzer` and VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring the `subjectivity` corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot.tok.gt9.5000', 'quote.tok.gt9.5000']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import subjectivity\n",
    "\n",
    "subjectivity.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'movie', 'begins', 'in', 'the', 'past', 'where', 'a', 'young', 'boy', 'named', 'sam', 'attempts', 'to', 'save', 'celebi', 'from', 'a', 'hunter', '.'], ['emerging', 'from', 'the', 'human', 'psyche', 'and', 'showing', 'characteristics', 'of', 'abstract', 'expressionism', ',', 'minimalism', 'and', 'russian', 'constructivism', ',', 'graffiti', 'removal', 'has', 'secured', 'its', 'place', 'in', 'the', 'history', 'of', 'modern', 'art', 'while', 'being', 'created', 'by', 'artists', 'who', 'are', 'unconscious', 'of', 'their', 'artistic', 'achievements', '.'], ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity.sents('plot.tok.gt9.5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['smart', 'and', 'alert', ',', 'thirteen', 'conversations', 'about', 'one', 'thing', 'is', 'a', 'small', 'gem', '.'], ['color', ',', 'musical', 'bounce', 'and', 'warm', 'seas', 'lapping', 'on', 'island', 'shores', '.', 'and', 'just', 'enough', 'science', 'to', 'send', 'you', 'home', 'thinking', '.'], ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity.sents('quote.tok.gt9.5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obj', 'subj']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity.categories() # The mapping between documents and categories does not depend on the file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'movie', 'begins', 'in', 'the', 'past', 'where', 'a', 'young', 'boy', 'named', 'sam', 'attempts', 'to', 'save', 'celebi', 'from', 'a', 'hunter', '.'], ['emerging', 'from', 'the', 'human', 'psyche', 'and', 'showing', 'characteristics', 'of', 'abstract', 'expressionism', ',', 'minimalism', 'and', 'russian', 'constructivism', ',', 'graffiti', 'removal', 'has', 'secured', 'its', 'place', 'in', 'the', 'history', 'of', 'modern', 'art', 'while', 'being', 'created', 'by', 'artists', 'who', 'are', 'unconscious', 'of', 'their', 'artistic', 'achievements', '.'], ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity.sents(categories='obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['smart', 'and', 'alert', ',', 'thirteen', 'conversations', 'about', 'one', 'thing', 'is', 'a', 'small', 'gem', '.'], ['color', ',', 'musical', 'bounce', 'and', 'warm', 'seas', 'lapping', 'on', 'island', 'shores', '.', 'and', 'just', 'enough', 'science', 'to', 'send', 'you', 'home', 'thinking', '.'], ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity.sents(categories='subj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building and testing a classifier with `SentimentAnalyzer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.sentiment import SentimentAnalyzer # SentimentAnalyzer is a tool to implement and facilitate Sentiment Analysis.\n",
    "from nltk.sentiment.util import (mark_negation, extract_unigram_feats) # mark_negation(): Append _NEG suffix to words that appear in the scope between a negation and a punctuation mark. extract_unigram_feats(): Populate a dictionary of unigram features, reflecting the presence/absence in the document of each of the tokens in unigrams.\n",
    "\n",
    "n_instances = 100\n",
    "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]\n",
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\n",
    "len(obj_docs), len(subj_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the',\n",
       "  'movie',\n",
       "  'begins',\n",
       "  'in',\n",
       "  'the',\n",
       "  'past',\n",
       "  'where',\n",
       "  'a',\n",
       "  'young',\n",
       "  'boy',\n",
       "  'named',\n",
       "  'sam',\n",
       "  'attempts',\n",
       "  'to',\n",
       "  'save',\n",
       "  'celebi',\n",
       "  'from',\n",
       "  'a',\n",
       "  'hunter',\n",
       "  '.'],\n",
       " 'obj')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj_docs = obj_docs[:80]\n",
    "test_obj_docs = obj_docs[80:100]\n",
    "train_subj_docs = subj_docs[:80]\n",
    "test_subj_docs = subj_docs[80:100]\n",
    "\n",
    "training_docs = train_obj_docs + train_subj_docs\n",
    "testing_docs = test_obj_docs + test_subj_docs\n",
    "\n",
    "sentiment_analyzer = SentimentAnalyzer()\n",
    "all_words_neg = sentiment_analyzer.all_words([mark_negation(doc) for doc in training_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_feats = sentiment_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
    "len(unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'contains(.)': True,\n",
       "  'contains(the)': True,\n",
       "  'contains(,)': False,\n",
       "  'contains(a)': True,\n",
       "  'contains(and)': False,\n",
       "  'contains(of)': False,\n",
       "  'contains(to)': True,\n",
       "  'contains(is)': False,\n",
       "  'contains(in)': True,\n",
       "  'contains(with)': False,\n",
       "  'contains(it)': False,\n",
       "  'contains(that)': False,\n",
       "  'contains(his)': False,\n",
       "  'contains(on)': False,\n",
       "  'contains(for)': False,\n",
       "  'contains(an)': False,\n",
       "  'contains(who)': False,\n",
       "  'contains(by)': False,\n",
       "  'contains(he)': False,\n",
       "  'contains(from)': True,\n",
       "  'contains(her)': False,\n",
       "  'contains(\")': False,\n",
       "  'contains(as)': False,\n",
       "  'contains(film)': False,\n",
       "  'contains(movie)': True,\n",
       "  'contains(this)': False,\n",
       "  'contains(their)': False,\n",
       "  'contains(but)': False,\n",
       "  'contains(at)': False,\n",
       "  'contains(one)': False,\n",
       "  'contains(the_NEG)': False,\n",
       "  'contains(about)': False,\n",
       "  'contains(are)': False,\n",
       "  \"contains(there's)\": False,\n",
       "  'contains(story)': False,\n",
       "  'contains(()': False,\n",
       "  'contains(to_NEG)': False,\n",
       "  'contains(a_NEG)': False,\n",
       "  'contains(,_NEG)': False,\n",
       "  'contains(be)': False,\n",
       "  'contains(so)': False,\n",
       "  'contains())': False,\n",
       "  'contains(they)': False,\n",
       "  'contains(when)': False,\n",
       "  'contains(she)': False,\n",
       "  'contains(life)': False,\n",
       "  'contains(out)': False,\n",
       "  'contains(like)': False,\n",
       "  'contains(have)': False,\n",
       "  'contains(not)': False,\n",
       "  'contains(all)': False,\n",
       "  'contains(into)': False,\n",
       "  'contains(what)': False,\n",
       "  'contains(will)': False,\n",
       "  'contains(you)': False,\n",
       "  'contains(has)': False,\n",
       "  'contains(its)': False,\n",
       "  'contains(;)': False,\n",
       "  'contains(:)': False,\n",
       "  'contains(only)': False,\n",
       "  'contains(can)': False,\n",
       "  'contains(more)': False,\n",
       "  'contains(even)': False,\n",
       "  'contains(--)': False,\n",
       "  'contains(where)': True,\n",
       "  'contains(if)': False,\n",
       "  'contains(him)': False,\n",
       "  'contains(search)': False,\n",
       "  'contains(look)': False,\n",
       "  'contains(home)': False,\n",
       "  \"contains(it's)\": False,\n",
       "  'contains(most)': False,\n",
       "  'contains(begins)': True,\n",
       "  'contains(of_NEG)': False,\n",
       "  'contains(some)': False,\n",
       "  'contains(two)': False,\n",
       "  'contains(made)': False,\n",
       "  'contains(make)': False,\n",
       "  'contains(both)': False,\n",
       "  'contains(them)': False,\n",
       "  'contains(which)': False,\n",
       "  'contains(love)': False,\n",
       "  'contains(but_NEG)': False},\n",
       " 'obj')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = sentiment_analyzer.apply_features(training_docs)\n",
    "test_set = sentiment_analyzer.apply_features(testing_docs)\n",
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentiment_analyzer.train(trainer, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.8\n",
      "F-measure [obj]: 0.8\n",
      "F-measure [subj]: 0.8\n",
      "Precision [obj]: 0.8\n",
      "Precision [subj]: 0.8\n",
      "Recall [obj]: 0.8\n",
      "Recall [subj]: 0.8\n"
     ]
    }
   ],
   "source": [
    "for key,value in sorted(sentiment_analyzer.evaluate(test_set).items()):\n",
    "    print('{0}: {1}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment analysis with `nltk.sentiment.vader.SentimentIntensityAnalyzer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a piece of shit, and I will step on you.\n",
      "compound: -0.5574, neg: 0.286, neu: 0.714, pos: 0.0, \n",
      "\n",
      "THIS SUCKS!\n",
      "compound: -0.4199, neg: 0.736, neu: 0.264, pos: 0.0, \n",
      "\n",
      "This kinda sux...\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "\n",
      "You're good, man!\n",
      "compound: 0.4926, neg: 0.0, neu: 0.385, pos: 0.615, \n",
      "\n",
      "DAMN, YOU ARE THE BEST! VERY FUNNY!!!\n",
      "compound: 0.7821, neg: 0.177, neu: 0.262, pos: 0.561, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sentences = [\n",
    "    \"You are a piece of shit, and I will step on you.\",\n",
    "    \"THIS SUCKS!\",\n",
    "    \"This kinda sux...\",\n",
    "    \"You're good, man!\",\n",
    "    \"DAMN, YOU ARE THE BEST! VERY FUNNY!!!\"\n",
    "            ]\n",
    "\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, `compound` represents the aggregated, final score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
