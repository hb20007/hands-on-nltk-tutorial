{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a POS Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train a classifier to work out which suffixes are most informative for POS tagging. We can begin by finding out what the most common suffixes are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'e': 202946, ',': 175002, '.': 152999, 's': 128722, 'd': 105687, 't': 94459, 'he': 92084, 'n': 87889, 'a': 74912, 'of': 72978, ...})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk import FreqDist\n",
    "\n",
    "suffix_f_dist = FreqDist()\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    suffix_f_dist[word[-1:]] += 1\n",
    "    suffix_f_dist[word[-2:]] += 1\n",
    "    suffix_f_dist[word[-3:]] += 1\n",
    "\n",
    "suffix_f_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_suffixes = [suffix for (suffix, _) in suffix_f_dist.most_common(100)]\n",
    "common_suffixes[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define a feature extractor function which checks a given word for these suffixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'endswith(e)': False,\n",
       " 'endswith(,)': False,\n",
       " 'endswith(.)': False,\n",
       " 'endswith(s)': False,\n",
       " 'endswith(d)': False,\n",
       " 'endswith(t)': True,\n",
       " 'endswith(he)': False,\n",
       " 'endswith(n)': False,\n",
       " 'endswith(a)': False,\n",
       " 'endswith(of)': False,\n",
       " 'endswith(the)': False,\n",
       " 'endswith(y)': False,\n",
       " 'endswith(r)': False,\n",
       " 'endswith(to)': False,\n",
       " 'endswith(in)': False,\n",
       " 'endswith(f)': False,\n",
       " 'endswith(o)': False,\n",
       " 'endswith(ed)': False,\n",
       " 'endswith(nd)': False,\n",
       " 'endswith(is)': False,\n",
       " 'endswith(on)': False,\n",
       " 'endswith(l)': False,\n",
       " 'endswith(g)': False,\n",
       " 'endswith(and)': False,\n",
       " 'endswith(ng)': False,\n",
       " 'endswith(er)': False,\n",
       " 'endswith(as)': False,\n",
       " 'endswith(ing)': False,\n",
       " 'endswith(h)': False,\n",
       " 'endswith(at)': False,\n",
       " 'endswith(es)': False,\n",
       " 'endswith(or)': False,\n",
       " 'endswith(re)': False,\n",
       " 'endswith(it)': False,\n",
       " 'endswith(``)': False,\n",
       " 'endswith(an)': False,\n",
       " \"endswith('')\": False,\n",
       " 'endswith(m)': False,\n",
       " 'endswith(;)': False,\n",
       " 'endswith(i)': False,\n",
       " 'endswith(ly)': False,\n",
       " 'endswith(ion)': False,\n",
       " 'endswith(en)': False,\n",
       " 'endswith(al)': False,\n",
       " 'endswith(?)': False,\n",
       " 'endswith(nt)': False,\n",
       " 'endswith(be)': False,\n",
       " 'endswith(hat)': False,\n",
       " 'endswith(st)': True,\n",
       " 'endswith(his)': False,\n",
       " 'endswith(th)': False,\n",
       " 'endswith(ll)': False,\n",
       " 'endswith(le)': False,\n",
       " 'endswith(ce)': False,\n",
       " 'endswith(by)': False,\n",
       " 'endswith(ts)': False,\n",
       " 'endswith(me)': False,\n",
       " 'endswith(ve)': False,\n",
       " \"endswith(')\": False,\n",
       " 'endswith(se)': False,\n",
       " 'endswith(ut)': False,\n",
       " 'endswith(was)': False,\n",
       " 'endswith(for)': False,\n",
       " 'endswith(ent)': False,\n",
       " 'endswith(ch)': False,\n",
       " 'endswith(k)': False,\n",
       " 'endswith(w)': False,\n",
       " 'endswith(ld)': False,\n",
       " 'endswith(`)': False,\n",
       " 'endswith(rs)': False,\n",
       " 'endswith(ted)': False,\n",
       " 'endswith(ere)': False,\n",
       " 'endswith(her)': False,\n",
       " 'endswith(ne)': False,\n",
       " 'endswith(ns)': False,\n",
       " 'endswith(ith)': False,\n",
       " 'endswith(ad)': False,\n",
       " 'endswith(ry)': False,\n",
       " 'endswith())': False,\n",
       " 'endswith(()': False,\n",
       " 'endswith(te)': False,\n",
       " 'endswith(--)': False,\n",
       " 'endswith(ay)': False,\n",
       " 'endswith(ty)': False,\n",
       " 'endswith(ot)': False,\n",
       " 'endswith(p)': False,\n",
       " 'endswith(nce)': False,\n",
       " \"endswith('s)\": False,\n",
       " 'endswith(ter)': False,\n",
       " 'endswith(om)': False,\n",
       " 'endswith(ss)': False,\n",
       " 'endswith(:)': False,\n",
       " 'endswith(we)': False,\n",
       " 'endswith(are)': False,\n",
       " 'endswith(c)': False,\n",
       " 'endswith(ers)': False,\n",
       " 'endswith(uld)': False,\n",
       " 'endswith(had)': False,\n",
       " 'endswith(so)': False,\n",
       " 'endswith(ey)': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos_features(word):\n",
    "    features = {}\n",
    "    for suffix in common_suffixes:\n",
    "        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
    "    return features\n",
    "\n",
    "pos_features('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined our feature extractor, we can use it to train a new decision tree classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'endswith(e)': True,\n",
       "  'endswith(,)': False,\n",
       "  'endswith(.)': False,\n",
       "  'endswith(s)': False,\n",
       "  'endswith(d)': False,\n",
       "  'endswith(t)': False,\n",
       "  'endswith(he)': True,\n",
       "  'endswith(n)': False,\n",
       "  'endswith(a)': False,\n",
       "  'endswith(of)': False,\n",
       "  'endswith(the)': True,\n",
       "  'endswith(y)': False,\n",
       "  'endswith(r)': False,\n",
       "  'endswith(to)': False,\n",
       "  'endswith(in)': False,\n",
       "  'endswith(f)': False,\n",
       "  'endswith(o)': False,\n",
       "  'endswith(ed)': False,\n",
       "  'endswith(nd)': False,\n",
       "  'endswith(is)': False,\n",
       "  'endswith(on)': False,\n",
       "  'endswith(l)': False,\n",
       "  'endswith(g)': False,\n",
       "  'endswith(and)': False,\n",
       "  'endswith(ng)': False,\n",
       "  'endswith(er)': False,\n",
       "  'endswith(as)': False,\n",
       "  'endswith(ing)': False,\n",
       "  'endswith(h)': False,\n",
       "  'endswith(at)': False,\n",
       "  'endswith(es)': False,\n",
       "  'endswith(or)': False,\n",
       "  'endswith(re)': False,\n",
       "  'endswith(it)': False,\n",
       "  'endswith(``)': False,\n",
       "  'endswith(an)': False,\n",
       "  \"endswith('')\": False,\n",
       "  'endswith(m)': False,\n",
       "  'endswith(;)': False,\n",
       "  'endswith(i)': False,\n",
       "  'endswith(ly)': False,\n",
       "  'endswith(ion)': False,\n",
       "  'endswith(en)': False,\n",
       "  'endswith(al)': False,\n",
       "  'endswith(?)': False,\n",
       "  'endswith(nt)': False,\n",
       "  'endswith(be)': False,\n",
       "  'endswith(hat)': False,\n",
       "  'endswith(st)': False,\n",
       "  'endswith(his)': False,\n",
       "  'endswith(th)': False,\n",
       "  'endswith(ll)': False,\n",
       "  'endswith(le)': False,\n",
       "  'endswith(ce)': False,\n",
       "  'endswith(by)': False,\n",
       "  'endswith(ts)': False,\n",
       "  'endswith(me)': False,\n",
       "  'endswith(ve)': False,\n",
       "  \"endswith(')\": False,\n",
       "  'endswith(se)': False,\n",
       "  'endswith(ut)': False,\n",
       "  'endswith(was)': False,\n",
       "  'endswith(for)': False,\n",
       "  'endswith(ent)': False,\n",
       "  'endswith(ch)': False,\n",
       "  'endswith(k)': False,\n",
       "  'endswith(w)': False,\n",
       "  'endswith(ld)': False,\n",
       "  'endswith(`)': False,\n",
       "  'endswith(rs)': False,\n",
       "  'endswith(ted)': False,\n",
       "  'endswith(ere)': False,\n",
       "  'endswith(her)': False,\n",
       "  'endswith(ne)': False,\n",
       "  'endswith(ns)': False,\n",
       "  'endswith(ith)': False,\n",
       "  'endswith(ad)': False,\n",
       "  'endswith(ry)': False,\n",
       "  'endswith())': False,\n",
       "  'endswith(()': False,\n",
       "  'endswith(te)': False,\n",
       "  'endswith(--)': False,\n",
       "  'endswith(ay)': False,\n",
       "  'endswith(ty)': False,\n",
       "  'endswith(ot)': False,\n",
       "  'endswith(p)': False,\n",
       "  'endswith(nce)': False,\n",
       "  \"endswith('s)\": False,\n",
       "  'endswith(ter)': False,\n",
       "  'endswith(om)': False,\n",
       "  'endswith(ss)': False,\n",
       "  'endswith(:)': False,\n",
       "  'endswith(we)': False,\n",
       "  'endswith(are)': False,\n",
       "  'endswith(c)': False,\n",
       "  'endswith(ers)': False,\n",
       "  'endswith(uld)': False,\n",
       "  'endswith(had)': False,\n",
       "  'endswith(so)': False,\n",
       "  'endswith(ey)': False},\n",
       " 'AT')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words = brown.tagged_words(categories='news')\n",
    "feature_sets = [(pos_features(n), g) for (n,g) in tagged_words]\n",
    "feature_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import DecisionTreeClassifier\n",
    "from nltk.classify import accuracy\n",
    "\n",
    "cutoff = int(len(feature_sets) * 0.1)\n",
    "train_set, test_set = feature_sets[cutoff:], feature_sets[:cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier.train(train_set) # NLTK is a teaching toolkit which is not really optimized for speed. Therefore, this may take forever. For speed, use scikit-learn for the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6270512182993535"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NNS'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(pos_features('cats'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if endswith(the) == False: \\n  if endswith(,) == False: \\n    if endswith(s) == False: \\n      if endswith(.) == False: return '.'\\n      if endswith(.) == True: return '.'\\n    if endswith(s) == True: \\n      if endswith(is) == False: return 'PP$'\\n      if endswith(is) == True: return 'BEZ'\\n  if endswith(,) == True: return ','\\nif endswith(the) == True: return 'AT'\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.pseudocode(depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the classifier, we can add contextual features:\n",
    "\n",
    "```py\n",
    "def pos_features(sentence, i): [1]\n",
    "    features = {\"suffix(1)\": sentence[i][-1:],\n",
    "                \"suffix(2)\": sentence[i][-2:],\n",
    "                \"suffix(3)\": sentence[i][-3:]}\n",
    "    if i == 0:\n",
    "        features[\"prev-word\"] = \"<START>\"\n",
    "    else:\n",
    "        features[\"prev-word\"] = sentence[i-1]\n",
    "    return features\n",
    "```\n",
    "\n",
    "Then, instead of working with tagged words, we work with tagged sentences:\n",
    "```py\n",
    "tagged_sents = brown.tagged_sents(categories='news')\n",
    "```\n",
    "\n",
    "We can then improve this further by adding more features such as `prev-tag` etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
