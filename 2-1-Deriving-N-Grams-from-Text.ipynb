{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deriving N-Grams from Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [N-Gram-Based Text Categorization: Categorizing Text With Python](https://web.archive.org/web/20240714175307/https://blog.alejandronolla.com/2013/05/20/n-gram-based-text-categorization-categorizing-text-with-python/) by Alejandro Nolla.\n",
    "\n",
    "If you are unfamiliar with n-grams, I recommend reading the article [Language Detection using N-Grams\n",
    "](http://cloudmark.github.io/Language-Detection/) by Mark Galea before proceeding with this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Le temps est un grand maître, dit-on, le malheur est qu’il tue ses élèves.\"\n",
    "s = s.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `RegexpTokenizer`, which allows us to enter our own regexp to make sure we deal correctly with the accented letters and apostrophes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['le',\n",
       " 'temps',\n",
       " 'est',\n",
       " 'un',\n",
       " 'grand',\n",
       " 'maître',\n",
       " 'dit',\n",
       " 'on',\n",
       " 'le',\n",
       " 'malheur',\n",
       " 'est',\n",
       " 'qu’il',\n",
       " 'tue',\n",
       " 'ses',\n",
       " 'élèves']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(\"[a-zA-Z'’`éèî]+\")\n",
    "s_tokenized = tokenizer.tokenize(s)\n",
    "s_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('_', '_', '_', 'l'),\n",
       "  ('_', '_', 'l', 'e'),\n",
       "  ('_', 'l', 'e', '_'),\n",
       "  ('l', 'e', '_', '_'),\n",
       "  ('e', '_', '_', '_')],\n",
       " [('_', '_', '_', 't'),\n",
       "  ('_', '_', 't', 'e'),\n",
       "  ('_', 't', 'e', 'm'),\n",
       "  ('t', 'e', 'm', 'p'),\n",
       "  ('e', 'm', 'p', 's'),\n",
       "  ('m', 'p', 's', '_'),\n",
       "  ('p', 's', '_', '_'),\n",
       "  ('s', '_', '_', '_')]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "generated_4grams = []\n",
    "\n",
    "for word in s_tokenized:\n",
    "    generated_4grams.append(\n",
    "        list(\n",
    "            ngrams(\n",
    "                word, 4, pad_left=True, pad_right=True, left_pad_symbol='_', right_pad_symbol='_'\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "generated_4grams[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`generated_4grams` needs flattening since it’s supposed to be a list of 4-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_', '_', '_', 'l'),\n",
       " ('_', '_', 'l', 'e'),\n",
       " ('_', 'l', 'e', '_'),\n",
       " ('l', 'e', '_', '_'),\n",
       " ('e', '_', '_', '_'),\n",
       " ('_', '_', '_', 't'),\n",
       " ('_', '_', 't', 'e'),\n",
       " ('_', 't', 'e', 'm'),\n",
       " ('t', 'e', 'm', 'p'),\n",
       " ('e', 'm', 'p', 's'),\n",
       " ('m', 'p', 's', '_'),\n",
       " ('p', 's', '_', '_'),\n",
       " ('s', '_', '_', '_')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng_list_4grams = [word for sublist in generated_4grams for word in sublist]\n",
    "ng_list_4grams[:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Obtaining n-grams (`n` = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['___l',\n",
       " '__le',\n",
       " '_le_',\n",
       " 'le__',\n",
       " 'e___',\n",
       " '___t',\n",
       " '__te',\n",
       " '_tem',\n",
       " 'temp',\n",
       " 'emps',\n",
       " 'mps_',\n",
       " 'ps__',\n",
       " 's___']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, val in enumerate(ng_list_4grams):\n",
    "    ng_list_4grams[idx] = ''.join(val)\n",
    "ng_list_4grams[:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sorting the n-grams by frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now sort the n-grams by frequency and keep the 300 most popular n-grams. This number was suggested in one of the first papers about using n-grams for NLP, [N-Gram-Based Text Categorization](https://www.let.rug.nl/vannoord/TextCat/textcat.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e___', 4), ('s___', 3), ('t___', 3), ('___l', 2), ('__le', 2)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "freq_4grams = {}\n",
    "\n",
    "for ngram in ng_list_4grams:\n",
    "    if ngram not in freq_4grams:\n",
    "        freq_4grams.update({ngram: 1})\n",
    "    else:\n",
    "        freq_4grams.update({ngram: freq_4grams[ngram] + 1})\n",
    "\n",
    "freq_4grams_sorted = sorted(freq_4grams.items(), key=itemgetter(1), reverse=True)[0:300]\n",
    "freq_4grams_sorted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Obtaining n-grams for multiple values of n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get n-grams for `n` = 1, 2, 3, and 4, we can use `everygrams`. This requires the raw sentence (without punctuation), as opposed to the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'le temps est un grand maître dit on le malheur est qu’il tue ses élèves'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import everygrams\n",
    "\n",
    "s_clean = ' '.join(s_tokenized)\n",
    "s_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l',\n",
       " 'le',\n",
       " 'le_',\n",
       " 'e',\n",
       " 'e_',\n",
       " '_t',\n",
       " '_te',\n",
       " '_tem',\n",
       " 't',\n",
       " 'te',\n",
       " 'tem',\n",
       " 'temp',\n",
       " 'e',\n",
       " 'em',\n",
       " 'emp',\n",
       " 'emps',\n",
       " 'm',\n",
       " 'mp',\n",
       " 'mps',\n",
       " 'mps_',\n",
       " 'p',\n",
       " 'ps',\n",
       " 'ps_',\n",
       " 's',\n",
       " 's_']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ngram_extractor(sent):\n",
    "    return [\n",
    "        ''.join(ng)\n",
    "        for ng in everygrams(sent.replace(' ', '_ _'), 1, 4)\n",
    "        if ' ' not in ng and '\\n' not in ng and ng != ('_',)\n",
    "    ]\n",
    "\n",
    "\n",
    "ngram_extractor(s_clean)[:25]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
